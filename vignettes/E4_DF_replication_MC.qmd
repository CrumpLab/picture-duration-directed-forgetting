---
title: "E4_DF_replication_matt"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{E1_DF_Mixed}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
```

Data collected 3/2/23

# Load libraries

```{r}
library(pacman)
library(dplyr)
library(tidyverse)
library(jsonlite)
library(xtable)
library(data.table)
```

## Import Data

```{r}
# Read the text file from JATOS ...
read_file('data/E4/jatos_results_20230302160519.txt') %>%
  # ... split it into lines ...
  str_split('\n') %>% first() %>%
  # ... filter empty rows ...
  discard(function(x) x == '') %>%
  # ... parse JSON into a data.frame
  map_dfr(fromJSON, flatten=T) -> all_data
```

## Demographics

```{r}
library(tidyr)

demographics <- all_data %>%
  filter(trial_type == "survey-html-form") %>%
  select(ID,response) %>%
  unnest_wider(response) %>%
  mutate(age = as.numeric(age))

age_demographics <- demographics %>%
  summarize(mean_age = mean(age),
            sd_age = sd(age),
            min_age = min(age),
            max_age = max(age))

factor_demographics <- apply(demographics[-1], 2, table)

```

A total of `r dim(demographics)[1]` participants were recruited from Amazon's Mechanical Turk. Mean age was `r round(age_demographics$mean_age, digits=1)` (range = `r age_demographics$min_age` to `r age_demographics$max_age` ). There were `r as.numeric(factor_demographics$sex["female"])` females, and `r as.numeric(factor_demographics$sex["male"])` males. There were `r as.numeric(factor_demographics$hand["Right"])` right-handed participants, and `r as.numeric(factor_demographics$hand["Both"])+as.numeric(factor_demographics$hand["Left"])` left or both handed participants. `r as.numeric(factor_demographics$vision["Normal"])` participants reported normal vision, and `r as.numeric(factor_demographics$vision["Corrected"])` participants reported corrected-to-normal vision. `r as.numeric(factor_demographics$english["First"])` participants reported English as a first language, and `r as.numeric(factor_demographics$english["Second"])` participants reported English as a second language.

## Pre-processing

We are interested in including participants who attempted to perform the task to the best of their ability. We adopted the following exclusion criteria.

1.  Lower than 75% correct during the encoding task. This means that participants failed to correctly press the F or R keys on each trial.

```{r, eval= FALSE}
# select data from the study phase
study_accuracy <- all_data %>%
  filter(experiment_phase == "study",
         is.na(correct) == FALSE) %>%
  group_by(ID)%>%
  summarize(mean_correct = mean(correct))

study_excluded_subjects <- study_accuracy %>%
  filter(mean_correct < .75) %>%
  pull(ID)

ggplot(study_accuracy, aes(x=mean_correct))+
  coord_cartesian(xlim=c(0,1))+
  geom_vline(xintercept=.75)+
  geom_histogram()+
  ggtitle("Histogram of mean correct responses \n for each subject during study phase")

```

2.  More than 25% Null responses (120\*.25 = 30) during test. NULL responses mean that the participant did not respond on a test trial after 10 seconds.

```{r}
# select data from the study phase
test_null <- all_data %>%
  filter(experiment_phase == "test",
         response =="NULL") %>%
  group_by(ID) %>%
  count()

test_null_excluded <- test_null %>%
  filter(n > (120*.25)) %>%
  pull(ID)

ggplot(test_null, aes(x=n))+
  geom_vline(xintercept=30)+
  geom_histogram()+
  ggtitle("Histogram of count of null responses \n for each subject during test")

```

3.  Higher than 75% response bias in the recognition task. This suggests that participants were simply pressing the same button on most trials.

```{r}
test_response_bias <- all_data %>%
  filter(experiment_phase == "test",
         response !="NULL") %>%
  mutate(response = as.numeric(response)) %>%
  group_by(ID, response) %>%
  count() %>%
  pivot_wider(names_from = response,
              values_from = n,
              values_fill = 0) %>%
  mutate(bias = abs(`0` - `1`)/120)

test_response_bias_excluded <- test_response_bias %>%
  filter(bias > .75) %>%
  pull(ID)

ggplot(test_response_bias, aes(x=bias))+
  geom_vline(xintercept=.75)+
  geom_histogram()+
  ggtitle("Histogram of response bias \n for each subject during test phase")

```

4.  Making responses too fast during the recognition memory test, indicating that they weren't performing the task. We excluded participants whose mean RT was less than 300 ms.

```{r}
test_mean_rt <- all_data %>%
  filter(experiment_phase == "test",
         response !="NULL",
         rt != "NULL") %>%
  mutate(rt = as.numeric(rt)) %>%
  group_by(ID) %>%
  summarize(mean_RT = mean(rt))

test_mean_rt_excluded <- test_mean_rt %>%
  filter(mean_RT < 300) %>%
  pull(ID)

ggplot(test_mean_rt, aes(x=mean_RT))+
  geom_vline(xintercept=300)+
  geom_histogram()+
  ggtitle("Histogram of response bias \n for each subject during test phase")

```

5.  Subjects are included if they perform better than 55% correct on the novel lures.

```{r}
test_mean_novel_accuracy <- all_data %>%
  filter(experiment_phase == "test",
         test_condition == "novel") %>%
  mutate(correct = as.logical(correct)) %>%
  group_by(ID) %>%
  summarize(mean_correct = mean(correct))

test_mean_novel_accuracy_excluded <- test_mean_novel_accuracy %>%
  filter(mean_correct < .55) %>%
  pull(ID)

ggplot(test_mean_novel_accuracy, aes(x=mean_correct))+
  geom_vline(xintercept=.55)+
  geom_histogram()+
  ggtitle("Histogram of mean accuracy for novel lures \n for each subject during test phase")

```

## All exclusions

```{r}

all_excluded <- unique(c(#study_excluded_subjects,
                  test_null_excluded,
                  test_response_bias_excluded,
                  test_mean_rt_excluded,
                  test_mean_novel_accuracy_excluded))

length(all_excluded)

```

Our participants were recruited online and completed the experiment from a web browser. Our experiment script requests that participants attempt the task to the best of their ability. Nevertheless, it is possible that participants complete the experiment and submit data without attempting to complete the task as directed. We developed a set of criteria to exclude participants whose performance indicated they were not attempting the task as instructed. These criteria also allowed us to confirm that the participants we included in the analysis did attempt the task as instructed to the best of their ability. We adopted the following five criteria:

First, during the encoding phase participants responded to each instructional cue (to remember or forget the picture on each trial) by pressing "R" or "F" on the keyboard. This task demand further served as an attentional check. We excluded participants who scored lower than 75% correct on instructional cue identification responses. Second, participants who did not respond on more than 25% of trials in the recognition test were excluded. Third, we measured response bias (choosing the left or right picture) during the recognition test, and excluded participants who made 75% of their responses to one side (indicating they were repeatedly pressing the same button on each trial). Fourth, we excluded participants whose mean reaction time during the recognition test was less than 300ms, indicating they were pressing the buttons as fast as possible without making a recognition decision. Finally, we computed mean accuracy for the novel lure condition for all participants, and excluded participants whose mean accuracy was less than 55% for those items. All together `r length(all_excluded)` participants were excluded.

# Accuracy analysis

## Define Helper functions

To do, consider moving the functions into the R package for this project

```{r}
# attempt general solution

## Declare helper functions

################
# get_mean_sem
# data = a data frame
# grouping_vars = a character vector of factors for analysis contained in data
# dv = a string indicated the dependent variable colunmn name in data
# returns data frame with grouping variables, and mean_{dv}, sem_{dv}
# note: dv in mean_{dv} and sem_{dv} is renamed to the string in dv

get_mean_sem <- function(data, grouping_vars, dv, digits=3){
  a <- data %>%
    group_by_at(grouping_vars) %>%
    summarize("mean_{ dv }" := round(mean(.data[[dv]]), digits),
              "sem_{ dv }" := round(sd(.data[[dv]])/sqrt(length(.data[[dv]])),digits),
              .groups="drop")
  return(a)
}

################
# get_effect_names
# grouping_vars = a character vector of factors for analysis
# returns a named list
# list contains all main effects and interaction terms
# useful for iterating the computation means across design effects and interactions

get_effect_names <- function(grouping_vars){
  effect_names <- grouping_vars
  if( length(grouping_vars > 1) ){
    for( i in 2:length(grouping_vars) ){
      effect_names <- c(effect_names,apply(combn(grouping_vars,i),2,paste0,collapse=":"))
    }
  }
  effects <- strsplit(effect_names, split=":")
  names(effects) <- effect_names
  return(effects)
}

################
# print_list_of_tables
# table_list = a list of named tables
# each table is printed 
# names are header level 3

print_list_of_tables <- function(table_list){
  for(i in 1:length(table_list)){
    cat("###",names(table_list[i]))
    cat("\n")
    print(knitr::kable(table_list[[i]]))
    cat("\n")
  }
}
```

## Design mutation

```{r}
# extract between-subject condition (button vs. no-button pressing to instructional cue)
IDs_between <- all_data %>%
  filter(grepl("Part I Instructions",stimulus)) %>%
  mutate(instructional_response = case_when(grepl("R button on the keyboard",stimulus) ~ "button",
                                            !grepl("R button on the keyboard",stimulus) ~ "no_button")) %>%
  select(ID,instructional_response)

all_data <- left_join(all_data,IDs_between,"ID")

```


## Conduct Analysis

```{r}

# create list to hold results
Accuracy <- list()

# Pre-process data for analysis
# assign to "filtered_data" object
Accuracy$filtered_data <- all_data %>%
  filter(experiment_phase == "test", 
         ID %in% all_excluded == FALSE)

# declare factors, IVS, subject variable, and DV
Accuracy$factors$IVs <- c("instructional_response",
                          "encoding_instruction",
                          "test_item_item_type")
Accuracy$factors$subject <- "ID"
Accuracy$factors$DV <- "correct"

## Subject-level means used for ANOVA
# get individual subject means for each condition
Accuracy$subject_means <- get_mean_sem(data=Accuracy$filtered_data,
                                       grouping_vars = c(Accuracy$factors$subject,
                                                         Accuracy$factors$IVs),
                                       dv = Accuracy$factors$DV)
## Condition-level means
# get all possible main effects and interactions
Accuracy$effects <- get_effect_names(Accuracy$factors$IVs)

Accuracy$means <- lapply(Accuracy$effects, FUN = function(x) {
  get_mean_sem(data=Accuracy$filtered_data,
             grouping_vars = x,
             dv = Accuracy$factors$DV)
})

## ANOVA

# ensure factors are factor class
Accuracy$subject_means <- Accuracy$subject_means %>%
  mutate_at(Accuracy$factors$IVs,factor) %>%
  mutate_at(Accuracy$factors$subject,factor)

# run ANOVA
Accuracy$aov.out <- aov(mean_correct ~ instructional_response*encoding_instruction*test_item_item_type + Error(ID/(encoding_instruction*test_item_item_type)), Accuracy$subject_means)

# save printable summaries
Accuracy$apa_print <- papaja::apa_print(Accuracy$aov.out)

```

## Graphs

```{r}
Accuracy$graphs$figure <- ggplot(Accuracy$means$`instructional_response:encoding_instruction:test_item_item_type`, 
                                 aes(x=test_item_item_type,
                                     y=mean_correct,
                                     group=encoding_instruction,
                                     fill=encoding_instruction))+
  geom_bar(stat="identity", position="dodge")+
  geom_errorbar(aes(ymin = mean_correct-sem_correct,
                    ymax = mean_correct+sem_correct),
                width=.9, position=position_dodge2(width = 0.2, padding = 0.8))+
  facet_wrap(~instructional_response)+
  coord_cartesian(ylim=c(.4,1))+
  geom_hline(yintercept=.5)+
  scale_y_continuous(breaks = seq(0.4,1,.1))+
  theme_classic(base_size=12)+
  ylab("Proportion Correct")+
  xlab("Lure Type")+
  scale_fill_discrete(name = " Encoding \n Instruction") +
  ggtitle("E4: Proportion Correct by instructional_response, \n Encoding Instruction, and Lure Type")

Accuracy$graphs$figure
```

## Print ANOVA

```{r, results="asis"}
knitr::kable(xtable(summary(Accuracy$aov.out)))
```

## Print Means

```{r, results="asis"}
print_list_of_tables(Accuracy$means)
```



# Reaction Time Analysis

## Conduct Analysis

```{r}

# create list to hold results
RT <- list()

# Pre-process data for analysis
# assign to "filtered_data" object
RT$filtered_data <- all_data %>%
  filter(experiment_phase == "test", 
         ID %in% all_excluded == FALSE,
         rt != "NULL") %>%
  mutate(rt = as.numeric(rt))

# declare factors, IVS, subject variable, and DV
RT$factors$IVs <- c("instructional_response",
                          "encoding_instruction",
                          "test_item_item_type")
RT$factors$subject <- "ID"
RT$factors$DV <- "rt"

## Subject-level means used for ANOVA
# get individual subject means for each condition
RT$subject_means <- get_mean_sem(data=RT$filtered_data,
                                       grouping_vars = c(RT$factors$subject,
                                                         RT$factors$IVs),
                                       dv = RT$factors$DV)
## Condition-level means
# get all possible main effects and interactions
RT$effects <- get_effect_names(RT$factors$IVs)

RT$means <- lapply(RT$effects, FUN = function(x) {
  get_mean_sem(data=RT$filtered_data,
             grouping_vars = x,
             dv = RT$factors$DV)
})

## ANOVA

# ensure factors are factor class
RT$subject_means <- RT$subject_means %>%
  mutate_at(RT$factors$IVs,factor) %>%
  mutate_at(RT$factors$subject,factor)

# run ANOVA
RT$aov.out <- aov(mean_rt ~ instructional_response*encoding_instruction*test_item_item_type + Error(ID/(encoding_instruction*test_item_item_type)), RT$subject_means)

# save printable summaries
RT$apa_print <- papaja::apa_print(RT$aov.out)

```

## Graphs

```{r}
RT$graphs$figure <- ggplot(RT$means$`instructional_response:encoding_instruction:test_item_item_type`, 
                                 aes(x=test_item_item_type,
                                     y=mean_rt,
                                     group=encoding_instruction,
                                     fill=encoding_instruction))+
  geom_bar(stat="identity", position="dodge")+
  geom_errorbar(aes(ymin = mean_rt-sem_rt,
                    ymax = mean_rt+sem_rt),
                width=.9, position=position_dodge2(width = 0.2, padding = 0.8))+
  facet_wrap(~instructional_response)+
  coord_cartesian(ylim=c(1000,2000))+
  scale_y_continuous(breaks = seq(1000,2000,100))+
  theme_classic(base_size=12)+
  ylab("Mean RT (ms)")+
  xlab("Lure Type")+
  scale_fill_discrete(name = " Encoding \n Instruction") +
  ggtitle("E4: Mean RT by Instructional Response, \n Encoding Instruction, and Lure Type")

RT$graphs$figure
```

## Print ANOVA

```{r, results="asis"}
knitr::kable(xtable(summary(RT$aov.out)))
```

## Print Means

```{r, results="asis"}
print_list_of_tables(RT$means)
```


# mid-experiment judgments

```{r}

# extract between-subject condition (button vs. no-button pressing to instructional cue)
IDs_sliders <- all_data %>%
  filter(trial_type == "html-slider-response") %>%
  mutate(response = unlist(response)) %>%
  mutate(question_type = case_when(grepl("implement the remember",stimulus) ~ "remember_difficulty",
                                   grepl("implement the forget",stimulus) ~ "forget_difficulty",
                                   grepl("follow the instructions",stimulus) ~ "instruction_follow",
                                   grepl("did you begin to feel fatigued.",stimulus) ~ "fatigue")) %>%
  select(ID,response,question_type) %>%
  pivot_wider(names_from = "question_type", values_from = "response")
  

all_data <- left_join(all_data,IDs_sliders,"ID")


```


```{r}
#get individual df effects for exemplar condition
# create list to hold results
lm_Accuracy <- list()

# Pre-process data for analysis
# assign to "filtered_data" object
lm_Accuracy$filtered_data <- all_data %>%
  filter(experiment_phase == "test", 
         ID %in% all_excluded == FALSE)

# declare factors, IVS, subject variable, and DV
lm_Accuracy$factors$IVs <- c("instructional_response",
                          "encoding_instruction",
                          "test_item_item_type")
lm_Accuracy$factors$subject <- "ID"
lm_Accuracy$factors$DV <- "correct"

# get individual subject means for each condition
lm_Accuracy$subject_means <-
  get_mean_sem(
    data = Accuracy$filtered_data,
    grouping_vars = c(Accuracy$factors$subject,
                      Accuracy$factors$IVs),
    dv = Accuracy$factors$DV
  )

# compute directed forgetting difference score for exemplar items for each subject
df_effects <- lm_Accuracy$subject_means %>%
  filter(test_item_item_type == "exemplar") %>%
  select(!sem_correct) %>%
  pivot_wider(names_from = encoding_instruction, 
              values_from = mean_correct ) %>%
  mutate(DF_exemplar = R-F)

df_effects <- left_join(df_effects,IDs_sliders,"ID")

# plots

ggplot(df_effects, aes(x=remember_difficulty, y = DF_exemplar)) +
  geom_point()+
  geom_smooth(method=lm)

summary(lm(DF_exemplar ~ remember_difficulty, df_effects))

ggplot(df_effects, aes(x=forget_difficulty, y = DF_exemplar)) +
  geom_point()+
  geom_smooth(method=lm)

summary(lm(DF_exemplar ~ forget_difficulty, df_effects))

ggplot(df_effects, aes(x=instruction_follow, y = DF_exemplar)) +
  geom_point()+
  geom_smooth(method=lm)

summary(lm(DF_exemplar ~ instruction_follow, df_effects))

ggplot(df_effects, aes(x=fatigue, y = DF_exemplar)) +
  geom_point()+
  geom_smooth(method=lm)

summary(lm(DF_exemplar ~ fatigue, df_effects))

summary(lm(DF_exemplar ~ remember_difficulty*forget_difficulty*instruction_follow*fatigue, df_effects))




```



## Instruction Switching Analysis

```{r, eval = FALSE}

# create list to hold results
Switching <- list()

# Pre-process data for analysis
# assign to "filtered_data" object

# get all included participants
Switching$filtered_data <- all_data %>%
  filter(ID %in% all_excluded == FALSE)

# study data for each participant
# create n-1 instruction factor
# create switching factor
# Remove first encoding trial (no switch or repeat)

Switching$study_data <- Switching$filtered_data %>%
  filter(experiment_phase == "study", 
         item_type == "study") %>%
  mutate(encoding_instruction_n_1 = c(NA,encoding_instruction[-length(encoding_instruction)])) %>%
  mutate(instruction_switch = case_when(encoding_instruction == encoding_instruction_n_1 ~ "Repeat",
                                        encoding_instruction != encoding_instruction_n_1 ~ "Switch")) %>%
  filter(trial_index != 7)

#View(Switching$study_data)
#dim(Switching$study_data)
#length(unique(Switching$study_data$ID))

# Add switching factor to test data for each trial and participant.

Switching$test_data <- Switching$filtered_data %>%
  filter(experiment_phase == "test") 

selected_study <- Switching$study_data %>%
  select(ID,image_name,encoding_instruction_n_1,instruction_switch) %>%
  rename("study_item_image_name" = "image_name") %>%
  filter(is.na(instruction_switch) == FALSE)

Switching$test_data <- left_join(Switching$test_data, selected_study,by=c("ID","study_item_image_name"))

#View(Switching$test_data)

```

```{r, eval= FALSE}

# declare factors, IVS, subject variable, and DV

Switching$factors$IVs <- c("encoding_instruction",
                          "instruction_switch",
                          "test_condition")
Switching$factors$subject <- "ID"
Switching$factors$DV <- "correct"

## Subject-level means used for ANOVA
# get individual subject means for each condition
Switching$subject_means <- get_mean_sem(
  data = Switching$test_data,
  grouping_vars = c(Switching$factors$subject,
                    Switching$factors$IVs),
  dv = Switching$factors$DV
)

## Condition-level means
# get all possible main effects and interactions
Switching$effects <- get_effect_names(Switching$factors$IVs)

Switching$means <- lapply(Switching$effects, FUN = function(x) {
  get_mean_sem(data=Switching$test_data,
             grouping_vars = x,
             dv = Switching$factors$DV)
})

Switching$means

```

## save environment

```{r, eval=FALSE}
save.image("data/E4/E4_data_write_up_MC.RData")
```
